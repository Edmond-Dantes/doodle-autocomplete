{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d29eda5",
   "metadata": {},
   "source": [
    "# Impute Images Script\n",
    "After creating a bunch of image data like this:\n",
    "https://openprocessing.org/sketch/2707919\n",
    "\n",
    "Create a folder by this notebook, then adjust the path below and run the function.\n",
    "Run the final cell to save the images as a numpy array that the model can accept in its current form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (511, 784)\n",
      "First row snippet: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def images_to_numpy(folder_path, size=(28, 28), normalize=True):\n",
    "    \"\"\"\n",
    "    Convert all images in a folder into a NumPy array of flattened grayscale vectors.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): path to the folder with images\n",
    "        size (tuple): target size, default (28, 28)\n",
    "        normalize (bool): if True, scale values to [0,1] floats\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (N, size[0]*size[1]) where N = number of images\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            path = os.path.join(folder_path, fname)\n",
    "\n",
    "            # open, convert to grayscale, resize\n",
    "            img = Image.open(path).convert(\"L\").resize(size)\n",
    "\n",
    "            arr = np.array(img, dtype=np.float32)\n",
    "\n",
    "            # normalize if requested\n",
    "            if normalize:\n",
    "                arr = arr / 255.0\n",
    "\n",
    "            # flatten\n",
    "            data.append(arr.flatten())\n",
    "\n",
    "    return np.vstack(data)\n",
    "\n",
    "# Example usage:\n",
    "folder = \"Images/\" #UPDATE to your folder name where your images to convert are stored\n",
    "X = images_to_numpy(folder) #also pass normalize=False if your images are already greyscale (most are RGB)\n",
    "\n",
    "print(\"Shape:\", X.shape)      # e.g. (number_of_images, 784)\n",
    "print(\"First row snippet:\", X[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f5cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved (511, 784) array to my_p5_images.npy\n"
     ]
    }
   ],
   "source": [
    "# --- Save to disk ---\n",
    "out_path = \"my_p5_images.npy\" #update the file name\n",
    "np.save(out_path, X)\n",
    "\n",
    "print(f\"Saved {X.shape} array to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3c285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (511, 784)\n"
     ]
    }
   ],
   "source": [
    "# --- Load it back (example) ---\n",
    "# X_loaded = np.load(out_path)\n",
    "# print(\"Loaded shape:\", X_loaded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07404b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick one example from your loaded array\n",
    "# idx = 0   # change this index to see different images\n",
    "# img = X_loaded[idx].reshape(28, 28)\n",
    "\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doodle-autocomplete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
